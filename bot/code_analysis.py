from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
import torch
from chardet import detect
import logging
import os
from datetime import datetime
import re
import warnings

# –§–∏–ª—å—Ç—Ä –≤—Å–µ—Ö –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
warnings.filterwarnings("ignore")
logging.getLogger("transformers").setLevel(logging.ERROR)

class CodeAnalyzer:
    def __init__(self, model_name, rag_db_path):
        self.logger = logging.getLogger(__name__)
        self.model_name = model_name
        self.generator = None  # –ö–æ–Ω–≤–µ–π–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–∞–∫ –∫–æ–Ω–≤–µ–π–µ—Ä
            self._init_generator()
            
            # –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π RAG (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            self.rag_db = self._init_rag_db(rag_db_path)
            
        except Exception as e:
            self.logger.critical(f"Init error: {str(e)}")
            raise

    def _init_generator(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∫–∞–∫ –∫–æ–Ω–≤–µ–π–µ—Ä–∞"""
        device = 0 if torch.cuda.is_available() else -1
        self.generator = pipeline(
            "text-generation",
            model=self.model_name,
            tokenizer=self.tokenizer,
            device=device,
            torch_dtype=torch.float16 if device == 0 else torch.float32,
            trust_remote_code=True
        )

    def _init_rag_db(self, path):
        if not path or not os.path.exists(path):
            return None
            
        try:
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-mpnet-base-v2",
                model_kwargs={"device": "cuda" if torch.cuda.is_available() else "cpu"}
            )
            return FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)
        except Exception as e:
            self.logger.warning(f"RAG init failed: {str(e)}")
            return None

    def analyze_file(self, file_path: str) -> str:
        try:
            if self._should_skip(file_path):
                return "‚ÑπÔ∏è File skipped (binary/system)"
                
            code = self._read_file_content(file_path)  # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥
            if not code:
                return "‚ö†Ô∏è Failed to read file"
                
            return self._fast_generate_analysis(file_path, code)
            
        except Exception as e:
            self.logger.error(f"Analysis failed: {str(e)}")
            return f"‚ö†Ô∏è Analysis error: {str(e)}"

    def _should_skip(self, file_path):
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º—ã—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
        skip_exts = {
            '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.zip', '.rar',
            '.exe', '.dll', '.so', '.bin', '.pdf', '.ttf', '.woff', '.woff2',
            '.eot', '.otf', '.mp3', '.wav', '.mp4', '.avi', '.mov', '.doc',
            '.docx', '.xls', '.xlsx', '.pyc', '.gitignore', '.md', '.ini', '.txt'
        }
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º .git —Ñ–∞–π–ª—ã –∏ –±–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã
        if '/.git/' in file_path.replace('\\', '/'):
            return True
            
        ext = os.path.splitext(file_path)[1].lower()
        if ext in skip_exts:
            return True
            
        return False

    # –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ù–´–ô –ú–ï–¢–û–î
    def _read_file_content(self, file_path):
        try:
            with open(file_path, 'rb') as f:
                raw = f.read()
                encoding = detect(raw)['encoding'] or 'utf-8'
                return raw.decode(encoding, errors='replace')
        except Exception as e:
            self.logger.error(f"Error reading file {file_path}: {str(e)}")
            return None

    def _fast_generate_analysis(self, file_path, code):
        """–ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω–≤–µ–π–µ—Ä–∞"""
        max_tokens = 3000
        encoded = self.tokenizer.encode(code)
        if len(encoded) > max_tokens:
            code = self.tokenizer.decode(
                encoded[:max_tokens],
                skip_special_tokens=True
            ) + "\n\n... [–∫–æ–¥ —É—Å–µ—á–µ–Ω –∏–∑-–∑–∞ –¥–ª–∏–Ω—ã]"
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∂—ë—Å—Ç–∫–∏–º —Ñ–æ—Ä–º–∞—Ç–æ–º
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥ –∏–∑ —Ñ–∞–π–ª–∞ {os.path.basename(file_path)} –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –æ—Ç—á—ë—Ç –°–¢–†–û–ì–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

[–Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞]
(—Ç–∏–ø –ø—Ä–æ–±–ª–µ–º—ã)
[—Å—Ç—Ä–æ—á–∫–∞: —Ç–æ—á–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –∫–æ–¥–∞ —Å –ø—Ä–æ–±–ª–µ–º–æ–π]
[–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –∫–æ–¥–∞]

–ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ, –ø–µ—Ä–µ—á–∏—Å–ª–∏ –∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ. –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç, –Ω–∞–ø–∏—à–∏ "–ü—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ".

–ü—Ä–∏–º–µ—Ä:
[config.py]
(–ø—Ä–æ–±–ª–µ–º–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
[—Å—Ç—Ä–æ—á–∫–∞: SECRET_KEY = 'password123']
[–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: SECRET_KEY = os.environ.get('SECRET_KEY')]

–ö–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{code}"""

        try:
            result = self.generator(
                prompt,
                max_new_tokens=600,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                temperature=1,     # –ü–æ–Ω–∏–∂–µ–Ω–∞ "–∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å"
                top_p=0.85,
                do_sample=True,
                num_return_sequences=1,
                pad_token_id=self.tokenizer.eos_token_id
            )
            
            response = result[0]['generated_text']
            response = response.replace(prompt, "", 1).strip()
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            response = re.sub(r"### (–û—Ç–≤–µ—Ç|Response|Ask|Question):.*", "", response, flags=re.IGNORECASE)
            return response
            
        except Exception as e:
            self.logger.error(f"Generation failed: {str(e)}")
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}"

    def generate_report(self, file_paths: list) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        final_report = "# –û—Ç—á—ë—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –∫–æ–¥–∞\n\n"
        valid_files = 0
        
        for path in file_paths:
            if not self._should_skip(path):
                clean_path = os.path.normpath(path).replace("\\", "/")
                analysis = self.analyze_file(path)
                
                if not analysis.strip():
                    analysis = "ü§∑ –ê–Ω–∞–ª–∏–∑ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–µ–Ω –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞."
                
                if analysis.startswith("‚ÑπÔ∏è") or analysis.startswith("‚ö†Ô∏è"):
                    final_report += f"## –§–∞–π–ª: `{clean_path}`\n{analysis}\n\n"
                    valid_files += 1
                    continue
                
                # –ü—Ä—è–º–æ–π –≤—ã–≤–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                final_report += f"## –§–∞–π–ª: `{clean_path}`\n{analysis}\n\n"
                valid_files += 1
                    
        if valid_files == 0:
            final_report += "‚ö†Ô∏è –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n"
            final_report += "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
            final_report += "- –í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–ø—É—â–µ–Ω—ã –∫–∞–∫ –±–∏–Ω–∞—Ä–Ω—ã–µ/—Å–∏—Å—Ç–µ–º–Ω—ã–µ\n"
            final_report += "- –û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤\n"
            final_report += "- –í —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ –∫–æ–¥–∞\n"
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        reports_dir = "data/reports"
        os.makedirs(reports_dir, exist_ok=True)
        
        final_path = os.path.join(reports_dir, f"report_{timestamp}.md")
        with open(final_path, "w", encoding="utf-8") as f:
            f.write(final_report)
            
        return final_path